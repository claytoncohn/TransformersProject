# TransformersProject
DS5899 Transformers Project

Identifying Educational Emotions via Speech Transformers.

## Overview (25 pts)
Two-minute overview providing context, stating the problem the project is addressing, characterizing the approach, and giving a brief account of how the problem was addressed.

[PowerPoint](https://github.com/claytoncohn/TransformersProject/blob/main/Overview.pptx) presentation.

## Critical Analysis (10 pts)
Answer one or more of the following questions: What is the impact of this project? What does it reveal or suggest? What is the next step?

See [PowerPoint](https://github.com/claytoncohn/TransformersProject/blob/main/Overview.pptx) presentation.

## Resource Links (10 pts)
Prepare links of where to go to get more information (other papers, models, blog posts (e.g. papers with code))

[Audeering on GitHub](https://github.com/audeering)

[Audeering on HuggingFace Hub](https://huggingface.co/audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim)

[Audeering Model Paper](https://arxiv.org/pdf/2203.07378.pdf)



## Code Demonstration (15 pts)
Make a Jupyter notebook demonstrating using the model.

See [repo](https://github.com/claytoncohn/TransformersProject).

## Repo (20 pts)
Prepare a repo with a readme, notebook, links to video, resources.

See [repo](https://github.com/claytoncohn/TransformersProject).

## Video Recording (10 pts)
Record a short video recording of the overview.

Video [link](https://youtu.be/ctVuRSNPwQk).

## First Week Bonus (15 pts)
Bonus for presenting on the first week. 

## References
<a id="1">[1]</a>
[Audeering. “Audeering/Wav2vec2-Large-Robust-12-Ft-Emotion-Msp-Dim.” Huggingface.co, HuggingFace, huggingface.co/audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim. Accessed 14 Nov. 2022.](https://huggingface.co/audeering/wav2vec2-large-robust-12-ft-emotion-msp-dim)
<br>
<a id="2">[2]</a>
[Wagner, Johannes, et al. "Dawn of the transformer era in speech emotion recognition: closing the valence gap." arXiv preprint arXiv:2203.07378 (2022).](https://arxiv.org/pdf/2203.07378.pdf)
<br>
<a id="3">[3]</a>
[Baevski, A., Zhou, H., Mohamed, A., and Auli, M., “wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations”, <i>arXiv e-prints</i>, 2020.](https://ai.facebook.com/blog/wav2vec-20-learning-the-structure-of-speech-from-raw-audio/)
<br>
<a id="4">[4]</a>
[Reza Lotfian and Carlos Busso, "Building naturalistic emotionally balanced speech corpus by retrieving emotional speech from existing podcast recordings," IEEE Transactions on Affective Computing, vol. 10, no. 4, pp. 471-483, October-December 2019.](https://ecs.utdallas.edu/research/researchlabs/msp-lab/MSP-Podcast.html)
